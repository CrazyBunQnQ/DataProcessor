# 知识库

## 地理位置库

- 把 MaxMind 的城市级地理库和本地中国行政区数据拼在一起，清洗、去重，最后生成两份 JSON：
- 一份是“城市/行政区清单”( Geography.json )，一份是“IP 段到城市的映射”( Geography_Ip.json )。

### 数据来源

- MaxMind GeoLite2 City CSV：通常解压后有 GeoLite2-City-Locations-zh-CN.csv 、 GeoLite2-City-Locations-en.csv 、 GeoLite2-City-Blocks-IPv4.csv 。
- 本地中国行政区资源： geo_cn/cn_region.csv （在 src/main/resources 下）。

### 处理顺序

- 载入中国行政区：读 cn_region.csv ，建立中国地区的层级关系（国家→省→市），并把 ID 统一补到 12 位，记录好父子关系。
- 读中文位置表：从 Locations-zh-CN.csv 取每行的国家、省、市，做归一化（省、市、自治区等后缀统一；台湾/香港/澳门纳入“中国”），并为每个 geoname_id 记下简名（优先城市）。
- 读英文位置表：从 Locations-en.csv 同步拿国家、省、市的英文，给后续英文名补齐做准备。
- 去重与ID规范化：以“国家 省 市”作为唯一键，遇到重复或冲突时，记录替换关系，确保同一地点只保留一个最终 ID。
- 生成城市清单：遍历 Blocks-IPv4.csv ，把能关联到地点的条目转成城市 JSON（带坐标、层级、英文名）；最后把中国行政区也追加进去。
- 补英文名：如果某条城市记录的英文名缺失或为空，就把中文名转为拼音补上（例如“北京市 朝阳区”→“Beijing Chaoyang”）。
- 生成 IP 映射：把 network （CIDR）换算成起止 IP（整数），找到对应地点，输出每个网段一行 JSON，带中文完整路径、英文完整路径、起止 IP 和自增行 ID。

### 输出字段

- Geography.json （数组）：
  - id ：城市/行政区唯一标识（城市用 geoname_id ，中国行政区用本地补齐的 12 位 ID）。
  - name ：简名（优先城市，其次省，再次国家）。
  - enName ：英文简名（优先用英文位置表；缺则由拼音补齐）。
  - parentId ：父级 ID（国家或省；不确定或与自身相同则 null ）。
  - latitude 、 longitude ：坐标（城市来自 Blocks 文件；中国行政区来自 cn_region.csv ）。
  - orderValue ：与 id 相同，用作排序。
- Geography_Ip.json （逐行对象）：
  - id ：自增的行号。
  - city ：中文完整路径（ 国家 省 市 ）。
  - enName ：英文完整路径（优先英文位置表；缺则可能为空或后续拼音补齐）。
  - start_ip 、 end_ip ：IP 范围（整数），由 CIDR 计算而来。

### TODO
ip 地理位置表增加字段
经纬度

地理位置库 编码去掉零，若涉及中国则不用 gid, 用国内统一编码


### 规则与注意

- 港澳台归属统一到“中国”，省名用原国家名以保持层级完整。
- 省市后缀统一（省/市/自治区/特别行政区等），避免同名不同写法导致映射失败。
- IP 到地点的关联有回退顺序： geoname_id 空时依次用“注册国家 ID”“代表国家 ID”。
- 输出前会清理特殊字符，避免 JSON 里出现不合法字符。
- 只处理 IPv4；IPv6不在当前管线。
- 中国行政区的根节点为 1814991 ；本地行政区 ID 会左补零到 12 位。

## 漏洞库

### 数据来源
- 读取多个从 cnnvd 下载的 XML 文件，每个文件里包含很多漏洞条目（`entry`）。
- 文件名里通常带月份标识（如 `当月`、`9月`、`8月` 或其他具体月份），用于判断优先级与更新覆盖顺序。
- 还会加载一个已有的总数据 JSON 文件（路径在脚本 `main()` 里配置），用于去重和继续自增 ID。

### 原始数据字段（XML）
- `entry`：每条漏洞记录的容器节点。
- `cve-id`：标准 CVE 编号。
- `vuln-id`：CNNVD 编号。
- `name`：漏洞标题。
- `vuln-descript`：漏洞描述（文本里可能混入特殊字符，脚本会先做修复再解析）。
- `published`：发布日期。
- `modified`：修改时间（同一个月份里比对谁更新，用这个字段决定覆盖）。
- `vuln-type`：漏洞/威胁类型。
- `severity`：严重程度（中文等级：超危 / 高危 / 中危 / 低危）。
- `vuln-solution`：处理建议或解决方案。

### 处理逻辑
- 先读“现有 JSON 数据”，把已出现过的 `CVE`/`CNNVD` 编号记下来，同时算出下一个可用的自增 `id`。
- 在 `data` 目录里找出全部 XML 文件，按文件名中的月份排序，保证“当月”最后处理，这样能覆盖前面月份的同一条漏洞。
- 为避免 XML 本身格式问题（如裸 `&` 或描述里带伪 HTML 标签），会对 `vuln-descript/name/vuln-solution` 的文本做转义修复，再进行解析。
- 逐条 `entry` 提取字段，整理成统一的字典结构；如果整文件解析失败，会退到“按 entry 片段解析”的兜底方式继续尽可能多地处理。
- 合并时用 `cve-id` 做唯一键：
  - 已在“现有数据”里出现过的直接跳过；
  - 同一个 `cve-id` 出现在多个 XML 文件时，按月份优先级覆盖；同月再比 `modified`，谁更新谁覆盖。
- 完成合并后，为每条新增数据顺序分配自增 `id`，然后写出 JSON 文件（数组形式，每行一个对象）。

### 去重与增量更新
- 去重依据：`cve-id`；同时用“现有 JSON”的 `cve-id` 集合做跳过判断。
- 覆盖策略：月份优先级为 `当月 > 9月 > 8月 > 其他`，同月用 `modified` 字符串大小比较来决定是否更新。
- ID 分配：读取现有数据的最大 `id`，新数据从它的下一个开始递增（以字符串形式保存）。

### 输出与保留字段（JSON）
- 基础标识：`id`（自增字符串）、`nvdCve`、`cve`、`cnnvd`。
- 标题与描述：`title`、`enTitle`（XML不提供，留空）、`vulnDescription`、`description`。
- 时间：`publishDate`、`pubDate`（均来自 `published`）。
- 类型与严重程度：`cnnvdThreatType`、`cnnvdType`、`level`（映射为 `CRITICAL/HIGH/MEDIUM/LOW`）、`severity`（映射为 `4/3/2/1`）。
- 解决方案：`solution`。
- 其他为保持与既有数据结构一致而保留、但通常为空的字段：`cpe`、`cvssScoreTwice`、`cvssVectorTwice`、`cvssScoreThird`、`cvssVectorThird`、`cwe`、`cweName`、`references`、`cnnvdUrl`、`threatName`、`reference`、`category`、`threatNameEng`、`descriptionEng`、`requirement`、`caused`、`valid`、`defaultAction`、`sid`、`deleted`。

### TODO
> cnnvd 下载最近几年的数据，只留 cnnvd 中有的字段，过去的数据不要了
> 奇安信情报中心的数据


## 威胁IP/URL数据库

### **数据来源**
- https://myip.ms/files/blacklist/general/latest_blacklist.txt

### **原始数据字段（每行）**
- 典型行示例：`185.26.173.9 # 2025-10-19, 185.26.173.9, SRB, 1`
- 字段含义：
  - `IP`：目标 IP 地址；
  - `日期`：`YYYY-MM-DD` 格式的发布日期；
  - `主机名`：可能为空或与 IP 相同；
  - `国家代码`：字符串国家/地区缩写（如 `SRB`、`US` 等）；
  - `黑名单类型ID`：整数类型编号。

### **处理逻辑**
- 载入已有数据：从当前目录的 `SSAThreatURL.json` 逐行加载旧数据，并按 `ip` 建索引，方便后续更新。
- 逐行解析：跳过注释和空行；解析出 IP、日期、主机名、国家代码、类型。
  - 日期会被转换为毫秒时间戳；
  - 黑名单类型数字会统一加 `1000`，用于与本地枚举常量对齐。
- 合并更新：同一个 `ip` 视为同一条记录；已有则覆盖更新，不存在则计为新增。
- 写回保存：将“旧有 + 新增 + 更新后的所有记录”按“每行一个 JSON 对象”的格式重写到 `SSAThreatURL.json`，并输出新增与更新条数统计。

### **拆分后保留的字段（JSON 行式）**
- `ip`：字符串，原始 IP。
- `publishDate`：整数，毫秒时间戳（由 `YYYY-MM-DD` 转换）。
- `url`：字符串，优先使用主机名；主机名为空时用 IP 字符串。
- `countryID`：字符串，国家/地区代码（如 `SRB`、`US` 等）。
- `blacklistType`：整数，原始黑名单类型 ID + `1000`。

### **增量合并与去重**
- 唯一键为 `ip`；相同 `ip` 的记录会被最新数据覆盖。
- 新出现的 `ip` 记为新增；最终保存的是完整集合（包含旧有与新增）。

## 威胁规则库

### 数据来源
- 官方开源规则包：从 Emerging Threats Open 下载 `suricata-{版本}/emerging.rules.tar.gz`（例如 `5.0.0`）。下载后直接在本地解压，得到 `rules/` 目录里的一堆 `.rules` 文件。

### 原始数据是什么 & 有哪些字段
- `.rules` 文件里，每条规则通常是一行，以 `alert` 或 `drop` 开头，括号里是分号分隔的“选项”。
- 重点关注的字段：
  - `msg`：告警信息（可读性最强的人类描述）。
  - `classtype`：规则分类（比如 `web-application-attack`、`trojan-activity` 等）。
  - `reference`：参考链接或编号（外部情报来源、漏洞编号等）。
  - 端口组变量名：规则条件里常出现的端口变量（形如 `$HTTP_PORTS`、`$DNS_PORTS`），便于后续提醒在配置里维护端口组。
- 其他常见字段（原样保留）：`sid`（规则 ID）、`rev`（规则版本）、`metadata`、`flow`、`content`、`pcre`、`threshold` 等。

### 处理流程
1. 根据 Suricata 版本，下载对应规则压缩包并解压
2. 遍历所有 `.rules` 文件，跳过少数不需要的文件（如 `emerging-deleted.rules`、`emerging-info.rules`、`tor.rules`）。
3. 处理每个源文件前，会在输出里写一行注释 `# 文件名`，方便后续回溯来源。
4. 对每条非注释行只处理以 `alert` 或 `drop` 开头的规则行，先抓取其中的 `msg`
5. 读取 `classtype`（用于某些场景的筛选），并收集该行中出现的端口组变量名（形如 `$*_PORTS`），累计形成一个清单。
6. 对 `msg` 做“去前缀”和规范化：把开头常见的厂商或标签前缀去掉或统一，比如 `ET EXPLOIT`、`GPL EXPLOIT`、`ET INFO`、`ET CNC`、`ATTACK_RESPONSE` 等，得到更简洁、直观的描述。
7. 翻译：调用翻译函数把简化后的 `msg` 翻译成更易读的中文描述。
8. 清理引用：删除该行中的 `reference:` 信息，减少冗余和噪音。
9. 写入：用翻译后的 `msg` 替换原来的 `msg`，其他字段保持不变，将整行写入统一输出文件 `csa.rules`。

### 最终输出
- 生成一个合并后的规则文件 `csa.rules`，内容还是原始规则，只是做了以下变化：
  - `msg`：被“去前缀+翻译”成更清晰的中文告警描述。
  - 其他字段（如 `classtype`、`sid`、`rev`、`metadata`、`content`、`pcre` 等）：全部保持原样。
  - 每个源 `.rules` 文件的开头，都有一行注释 `# 文件名`，便于定位来源。

### 过滤与规则选择
- 跳过的文件：`emerging-deleted.rules`、`emerging-info.rules`、`tor.rules`。
- 跳过的行：包含 `HTTP GET Request XOR Key` 或 `HTTP POST Request XOR Key` 的规则行不处理。

### 规则描述

- 逐行读取前面输出的合并文件（如 `csa.rules`）；跳过空行与注释；把整条规则行交给模型，按固定模板生成中文结果；再把结果写成一行存档。
- 生成描述
  - 模型返回一个简短的中文“描述”。
  - 产出内容以“字典字符串”的形式逐行写入目标文件，便于后续解析与去重。
- 输出描述文件
  - `sid`：规则 ID（唯一标识）。
  - `result`：该规则的中文简短描述或解释。

## 处置建议库

### 数据来源
- 来自前面输出的合并文件（如 `csa.rules`），或你指定的任何 `.rules` 文件。
- 大模型接口（如 OpenAI、通义千问、星火、讯飞、文心等）自动生成中文内容。
- 去重来源：从已存在的目标文件（如 `rules.sugst`）里读取已处理过的规则 ID，避免重复生成。

## 处理逻辑
- 通用流程：逐行读取规则；跳过空行与注释；把整条规则行交给模型，按固定模板生成中文结果；再把结果写成一行存档。
- 生成处置建议
  - 使用更严格的模板，让模型返回一个结构化的中文 JSON（包含标题、处置建议、危害和原理）。
  - 自动把规则里的 `classtype` 映射为一个整数类别（`type`），方便前端或服务端分类展示。
  - 为了应对模型偶尔返回带代码块或转义字符异常的情况，会先清洗 JSON，再解析写入。

## 输出

- 处置建议文件
  - `id`：规则唯一标识（与 `sid` 一类）。
  - `ruleNameList`：规则名列表（通常包含一个名称）。
  - `attack`：15 字以内的告警标题。
  - `advice`：处置建议与补偿性措施（要求针对规则匹配逻辑）。
  - `harm`：危害描述（简明扼要）。
  - `theory`：攻击原理简述。
  - `type`：根据 `classtype` 映射得到的整数类别索引。
  - `riskType`：风险类型标记（固定为 2）。